2025-01-14 21:32:58,063 - INFO - Loaded hyperparameters: [{'GPU_device': 'cuda:1', 'filter': True, 'num_epochs': 500, 'early_stop': 500, 'num_classes': 2, 'd_state': 16, 'd_conv': 2, 'expand': 8, 'scale_factor': 1, 'batch_size': 64}]. 

2025-01-14 21:32:58,063 - INFO - TUAB 

2025-01-14 21:32:58,216 - INFO - GPU: cuda:1
 model name: BrainMamba2_multibranch
2025-01-14 21:32:58,386 - INFO - Loaded TUAB dataset.
2025-01-14 21:32:59,584 - INFO - Layer input_embedding.branch1.weight: Shape torch.Size([64, 16, 1])
2025-01-14 21:32:59,584 - INFO - Layer input_embedding.branch1.bias: Shape torch.Size([64])
2025-01-14 21:32:59,584 - INFO - Layer input_embedding.branch3.weight: Shape torch.Size([64, 16, 3])
2025-01-14 21:32:59,584 - INFO - Layer input_embedding.branch3.bias: Shape torch.Size([64])
2025-01-14 21:32:59,584 - INFO - Layer input_embedding.branch7.weight: Shape torch.Size([64, 16, 7])
2025-01-14 21:32:59,584 - INFO - Layer input_embedding.branch7.bias: Shape torch.Size([64])
2025-01-14 21:32:59,584 - INFO - Layer input_embedding.fuse.weight: Shape torch.Size([64, 192, 1])
2025-01-14 21:32:59,584 - INFO - Layer input_embedding.fuse.bias: Shape torch.Size([64])
2025-01-14 21:32:59,585 - INFO - Total trainable parameters: 4565144

2025-01-14 21:32:59,585 - INFO - Model Summary: 
 BrainMamba2_multibranch(
  (input_embedding): MultiBranchInputEmbedding(
    (branch1): Conv1d(16, 64, kernel_size=(1,), stride=(1,))
    (branch3): Conv1d(16, 64, kernel_size=(3,), stride=(1,), padding=(1,))
    (branch7): Conv1d(16, 64, kernel_size=(7,), stride=(1,), padding=(3,))
    (fuse): Conv1d(192, 64, kernel_size=(1,), stride=(1,))
  )
  (encoder1): Sequential(
    (0): Linear(in_features=64, out_features=64, bias=True)
    (1): SelfSupervisedMambaModel(
      (mamba): Mamba2(
        (in_proj): Linear(in_features=64, out_features=1064, bias=False)
        (conv1d): Conv1d(544, 544, kernel_size=(2,), stride=(1,), padding=(1,), groups=544)
        (act): SiLU()
        (norm): RMSNorm()
        (out_proj): Linear(in_features=512, out_features=64, bias=False)
      )
      (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
    )
  )
  (pool1): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (encoder2): Conv1d(64, 128, kernel_size=(3,), stride=(1,), padding=(1,))
  (pool2): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (encoder3): Conv1d(128, 256, kernel_size=(3,), stride=(1,), padding=(1,))
  (pool3): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (bottleneck): Sequential(
    (0): Linear(in_features=256, out_features=256, bias=True)
    (1): SelfSupervisedMambaModel(
      (mamba): Mamba2(
        (in_proj): Linear(in_features=256, out_features=4160, bias=False)
        (conv1d): Conv1d(2080, 2080, kernel_size=(2,), stride=(1,), padding=(1,), groups=2080)
        (act): SiLU()
        (norm): RMSNorm()
        (out_proj): Linear(in_features=2048, out_features=256, bias=False)
      )
      (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    )
    (2): Linear(in_features=256, out_features=256, bias=True)
  )
  (decoder3): Conv1d(512, 256, kernel_size=(3,), stride=(1,), padding=(1,))
  (decodeMamba3): SelfSupervisedMambaModel(
    (mamba): Mamba2(
      (in_proj): Linear(in_features=256, out_features=4160, bias=False)
      (conv1d): Conv1d(2080, 2080, kernel_size=(2,), stride=(1,), padding=(1,), groups=2080)
      (act): SiLU()
      (norm): RMSNorm()
      (out_proj): Linear(in_features=2048, out_features=256, bias=False)
    )
    (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
  )
  (decoder2): Conv1d(384, 128, kernel_size=(3,), stride=(1,), padding=(1,))
  (decodeMamba2): SelfSupervisedMambaModel(
    (mamba): Mamba2(
      (in_proj): Linear(in_features=128, out_features=2096, bias=False)
      (conv1d): Conv1d(1056, 1056, kernel_size=(2,), stride=(1,), padding=(1,), groups=1056)
      (act): SiLU()
      (norm): RMSNorm()
      (out_proj): Linear(in_features=1024, out_features=128, bias=False)
    )
    (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
  )
  (decoder1): Conv1d(192, 64, kernel_size=(3,), stride=(1,), padding=(1,))
  (onput_embedding): Conv1d(64, 16, kernel_size=(1,), stride=(1,))
)

2025-01-14 21:32:59,585 - INFO - Training start.
2025-01-16 23:14:56,618 - INFO -  - Channel 1 MSE: 4.702180918941812e-12
2025-01-16 23:14:56,618 - INFO -  - Channel 2 MSE: 8.408578520968657e-12
2025-01-16 23:14:56,618 - INFO -  - Channel 3 MSE: 1.0459334787160657e-11
2025-01-16 23:14:56,618 - INFO -  - Channel 4 MSE: 7.672565707772527e-12
2025-01-16 23:14:56,618 - INFO -  - Channel 5 MSE: 3.512409807449046e-11
2025-01-16 23:14:56,618 - INFO -  - Channel 6 MSE: 4.811122420594893e-12
2025-01-16 23:14:56,618 - INFO -  - Channel 7 MSE: 3.6328902126153695e-12
2025-01-16 23:14:56,618 - INFO -  - Channel 8 MSE: 2.2589322773436393e-11
2025-01-16 23:14:56,619 - INFO -  - Channel 9 MSE: 2.4602375258558906e-12
2025-01-16 23:14:56,619 - INFO -  - Channel 10 MSE: 2.3531033024881687e-11
2025-01-16 23:14:56,619 - INFO -  - Channel 11 MSE: 3.4886856858235005e-12
2025-01-16 23:14:56,619 - INFO -  - Channel 12 MSE: 4.074314670365897e-12
2025-01-16 23:14:56,619 - INFO -  - Channel 13 MSE: 5.1253879612689346e-11
2025-01-16 23:14:56,619 - INFO -  - Channel 14 MSE: 1.350542334216387e-11
2025-01-16 23:14:56,619 - INFO -  - Channel 15 MSE: 8.513542301691324e-12
2025-01-16 23:14:56,619 - INFO -  - Channel 16 MSE: 3.970232129169027e-12
2025-01-16 23:14:56,619 - INFO -  - Average MSE across all channels computed from Original and Reconstructed ERPs: 1.626542513348604e-13
